ğŸš€ ReqMind AI
AI-Powered Business Requirements Document Generator

RAG | FastAPI | FAISS | Gemini | Cloud Deployment

ğŸ” Overview

ReqMind AI is a production-ready Retrieval-Augmented Generation (RAG) system that automatically transforms unstructured communication (meeting transcripts, emails, Slack chats) into structured, traceable, enterprise-grade Business Requirements Documents (BRDs).

It demonstrates applied skills in:

Large Language Models (LLMs)

RAG architecture design

Vector search (FAISS)

Prompt engineering

Backend API development (FastAPI)

Cloud deployment (Google Cloud Run)

System pipeline design

Confidence-based human-in-the-loop validation

ğŸ¯ Problem Statement

Requirement documentation in real-world projects is:

Manual and time-consuming

Prone to ambiguity and misinterpretation

Difficult to trace back to original discussions

Lacking structured conflict detection

ReqMind AI automates this process while preserving traceability and interpretability.

ğŸ—ï¸ System Architecture

The system is built as a 9-stage intelligent pipeline:

Input Ingestion â€“ Supports transcripts, email threads, Slack chats, AMI dataset

Rule-Based Preprocessing â€“ Speaker segmentation + filler removal

RAG Chunking â€“ Semantic chunk creation with overlap

Embedding Generation â€“ SentenceTransformers (MiniLM)

Vector Indexing â€“ FAISS for similarity search

LLM Extraction â€“ Gemini extracts structured requirements

Conflict Detection â€“ LLM-assisted contradiction detection

BRD Template Generation â€“ Structured enterprise-ready format

Executive Summary Generation â€“ Context-aware summarization

ğŸ§  Technical Stack
Component	Technology
Backend API	FastAPI
LLM	Gemini (gemini-2.0-flash)
Embeddings	all-MiniLM-L6-v2
Vector Database	FAISS
Deployment	Google Cloud Run
Containerization	Docker
ğŸ“Š Core Capabilities

âœ” Functional & Non-Functional Requirement Extraction
âœ” Stakeholder Identification & Sentiment Mapping
âœ” Timeline & Milestone Detection
âœ” Conflict & Risk Detection
âœ” Confidence Scoring per Requirement
âœ” Human-in-the-Loop (HITL) Flagging
âœ” Traceability Matrix Generation
âœ” Iterative AI-Based BRD Editing
âœ” Multi-source Input Normalization

Each requirement includes:

1. Unique ID

2. Source speaker

3. Timestamp

4. Confidence score

5. Source traceability

â˜ï¸ Deployment-Ready Architecture

The application is fully containerized and deployed on Google Cloud Run, demonstrating:

Environment-based configuration

Stateless API architecture

Production-safe CORS handling

Graceful LLM fallback handling (mock/live mode)

Rate limit resilience

ğŸ› ï¸ Running Locally
uvicorn main:app --reload --port 8000
ğŸ³ Docker
docker build -t reqmind-ai .
docker run -p 8000:8000 reqmind-ai
ğŸ“ˆ Engineering Highlights

Designed and implemented full RAG pipeline from scratch

Integrated FAISS vector search with semantic retrieval

Built structured JSON schema enforcement for LLM outputs

Implemented fallback handling for LLM rate limits

Designed confidence-based ambiguity flagging system

Developed enterprise-grade BRD templating engine

Ensured separation of rule-based vs LLM-driven logic


ğŸ“Œ Why This Project Matters

1. This project demonstrates:

2. Applied AI system design

3. Real-world NLP engineering

4. LLM production integration

5. Backend architecture skills

6. Cloud deployment knowledge

7. Strong understanding of requirement engineering workflows

8. It bridges AI research concepts with practical enterprise application.

ğŸ‘©â€ğŸ’» Team

CodeBlooded
HackFest 2.0 Submission
